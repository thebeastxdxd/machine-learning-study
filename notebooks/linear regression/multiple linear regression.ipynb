{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'D:\\\\Workspace\\\\machine-learning-study\\\\Machine Learning A-Z Template Folder\\\\Part 2 - Regression\\\\Section 5 - Multiple Linear Regression\\\\50_startups.csv'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "current_dir = Path(os.getcwd())\n",
    "\n",
    "parent_dir = str(current_dir.parents[1])\n",
    "#we will take as an example \\Machine Learning A-Z Template Folder\\Part 1 - Data Preprocessing\\Data_Preprocessing\n",
    "#make sure to take of the first \\ because if it is left there then it is considered an absolute path...\n",
    "data_url = r'Machine Learning A-Z Template Folder\\Part 2 - Regression\\Section 5 - Multiple Linear Regression\\50_startups.csv'\n",
    "path = os.path.join(parent_dir, data_url)\n",
    "\n",
    "path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>R&amp;D Spend</th>\n",
       "      <th>Administration</th>\n",
       "      <th>Marketing Spend</th>\n",
       "      <th>State</th>\n",
       "      <th>Profit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>165349.20</td>\n",
       "      <td>136897.80</td>\n",
       "      <td>471784.10</td>\n",
       "      <td>New York</td>\n",
       "      <td>192261.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>162597.70</td>\n",
       "      <td>151377.59</td>\n",
       "      <td>443898.53</td>\n",
       "      <td>California</td>\n",
       "      <td>191792.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>153441.51</td>\n",
       "      <td>101145.55</td>\n",
       "      <td>407934.54</td>\n",
       "      <td>Florida</td>\n",
       "      <td>191050.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>144372.41</td>\n",
       "      <td>118671.85</td>\n",
       "      <td>383199.62</td>\n",
       "      <td>New York</td>\n",
       "      <td>182901.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>142107.34</td>\n",
       "      <td>91391.77</td>\n",
       "      <td>366168.42</td>\n",
       "      <td>Florida</td>\n",
       "      <td>166187.94</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   R&D Spend  Administration  Marketing Spend       State     Profit\n",
       "0  165349.20       136897.80        471784.10    New York  192261.83\n",
       "1  162597.70       151377.59        443898.53  California  191792.06\n",
       "2  153441.51       101145.55        407934.54     Florida  191050.39\n",
       "3  144372.41       118671.85        383199.62    New York  182901.99\n",
       "4  142107.34        91391.77        366168.42     Florida  166187.94"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(path)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = data.iloc[:, :-1].values\n",
    "y = data.iloc[:, data.shape[1]-1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#first lets one hot encode this and take one out to avoid the dummy var trap\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "labelencoder_X = LabelEncoder()\n",
    "X[:, 3] = labelencoder_X.fit_transform(X[:, 3])\n",
    "onehotencoder = OneHotEncoder(categorical_features = [3]) # we give it the cols where we want the encoding to happen\n",
    "X = onehotencoder.fit_transform(X).toarray()\n",
    "X = X[:, 1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[  1.00000000e+00,   0.00000000e+00,   5.54939500e+04,\n",
       "           1.03057490e+05,   2.14634810e+05],\n",
       "        [  0.00000000e+00,   1.00000000e+00,   4.60140200e+04,\n",
       "           8.50474400e+04,   2.05517640e+05],\n",
       "        [  1.00000000e+00,   0.00000000e+00,   7.53288700e+04,\n",
       "           1.44135980e+05,   1.34050070e+05],\n",
       "        [  0.00000000e+00,   0.00000000e+00,   4.64260700e+04,\n",
       "           1.57693920e+05,   2.10797670e+05],\n",
       "        [  1.00000000e+00,   0.00000000e+00,   9.17491600e+04,\n",
       "           1.14175790e+05,   2.94919570e+05],\n",
       "        [  1.00000000e+00,   0.00000000e+00,   1.30298130e+05,\n",
       "           1.45530060e+05,   3.23876680e+05],\n",
       "        [  1.00000000e+00,   0.00000000e+00,   1.19943240e+05,\n",
       "           1.56547420e+05,   2.56512920e+05],\n",
       "        [  0.00000000e+00,   1.00000000e+00,   1.00023000e+03,\n",
       "           1.24153040e+05,   1.90393000e+03],\n",
       "        [  0.00000000e+00,   1.00000000e+00,   5.42050000e+02,\n",
       "           5.17431500e+04,   0.00000000e+00],\n",
       "        [  0.00000000e+00,   1.00000000e+00,   6.56054800e+04,\n",
       "           1.53032060e+05,   1.07138380e+05],\n",
       "        [  0.00000000e+00,   1.00000000e+00,   1.14523610e+05,\n",
       "           1.22616840e+05,   2.61776230e+05],\n",
       "        [  1.00000000e+00,   0.00000000e+00,   6.19944800e+04,\n",
       "           1.15641280e+05,   9.11312400e+04],\n",
       "        [  0.00000000e+00,   0.00000000e+00,   6.34088600e+04,\n",
       "           1.29219610e+05,   4.60852500e+04],\n",
       "        [  0.00000000e+00,   0.00000000e+00,   7.80131100e+04,\n",
       "           1.21597550e+05,   2.64346060e+05],\n",
       "        [  0.00000000e+00,   0.00000000e+00,   2.36409300e+04,\n",
       "           9.61896300e+04,   1.48001110e+05],\n",
       "        [  0.00000000e+00,   0.00000000e+00,   7.62538600e+04,\n",
       "           1.13867300e+05,   2.98664470e+05],\n",
       "        [  0.00000000e+00,   1.00000000e+00,   1.55057300e+04,\n",
       "           1.27382300e+05,   3.55341700e+04],\n",
       "        [  0.00000000e+00,   1.00000000e+00,   1.20542520e+05,\n",
       "           1.48718950e+05,   3.11613290e+05],\n",
       "        [  0.00000000e+00,   0.00000000e+00,   9.19923900e+04,\n",
       "           1.35495070e+05,   2.52664930e+05],\n",
       "        [  0.00000000e+00,   0.00000000e+00,   6.46647100e+04,\n",
       "           1.39553160e+05,   1.37962620e+05],\n",
       "        [  0.00000000e+00,   1.00000000e+00,   1.31876900e+05,\n",
       "           9.98147100e+04,   3.62861360e+05],\n",
       "        [  0.00000000e+00,   1.00000000e+00,   9.46571600e+04,\n",
       "           1.45077580e+05,   2.82574310e+05],\n",
       "        [  0.00000000e+00,   0.00000000e+00,   2.87543300e+04,\n",
       "           1.18546050e+05,   1.72795670e+05],\n",
       "        [  0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "           1.16983800e+05,   4.51730600e+04],\n",
       "        [  0.00000000e+00,   0.00000000e+00,   1.62597700e+05,\n",
       "           1.51377590e+05,   4.43898530e+05],\n",
       "        [  1.00000000e+00,   0.00000000e+00,   9.38637500e+04,\n",
       "           1.27320380e+05,   2.49839440e+05],\n",
       "        [  0.00000000e+00,   0.00000000e+00,   4.40699500e+04,\n",
       "           5.12831400e+04,   1.97029420e+05],\n",
       "        [  0.00000000e+00,   1.00000000e+00,   7.70440100e+04,\n",
       "           9.92813400e+04,   1.40574810e+05],\n",
       "        [  0.00000000e+00,   0.00000000e+00,   1.34615460e+05,\n",
       "           1.47198870e+05,   1.27716820e+05],\n",
       "        [  1.00000000e+00,   0.00000000e+00,   6.75325300e+04,\n",
       "           1.05751030e+05,   3.04768730e+05],\n",
       "        [  1.00000000e+00,   0.00000000e+00,   2.86637600e+04,\n",
       "           1.27056210e+05,   2.01126820e+05],\n",
       "        [  0.00000000e+00,   1.00000000e+00,   7.83894700e+04,\n",
       "           1.53773430e+05,   2.99737290e+05],\n",
       "        [  0.00000000e+00,   1.00000000e+00,   8.64197000e+04,\n",
       "           1.53514110e+05,   0.00000000e+00],\n",
       "        [  0.00000000e+00,   0.00000000e+00,   1.23334880e+05,\n",
       "           1.08679170e+05,   3.04981620e+05],\n",
       "        [  0.00000000e+00,   0.00000000e+00,   3.85585100e+04,\n",
       "           8.29820900e+04,   1.74999300e+05],\n",
       "        [  1.00000000e+00,   0.00000000e+00,   1.31546000e+03,\n",
       "           1.15816210e+05,   2.97114460e+05],\n",
       "        [  0.00000000e+00,   1.00000000e+00,   1.44372410e+05,\n",
       "           1.18671850e+05,   3.83199620e+05],\n",
       "        [  0.00000000e+00,   1.00000000e+00,   1.65349200e+05,\n",
       "           1.36897800e+05,   4.71784100e+05],\n",
       "        [  0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "           1.35426920e+05,   0.00000000e+00],\n",
       "        [  0.00000000e+00,   0.00000000e+00,   2.21777400e+04,\n",
       "           1.54806140e+05,   2.83347200e+04]]),\n",
       " array([[  1.00000000e+00,   0.00000000e+00,   6.60515200e+04,\n",
       "           1.82645560e+05,   1.18148200e+05],\n",
       "        [  0.00000000e+00,   0.00000000e+00,   1.00671960e+05,\n",
       "           9.17906100e+04,   2.49744550e+05],\n",
       "        [  1.00000000e+00,   0.00000000e+00,   1.01913080e+05,\n",
       "           1.10594110e+05,   2.29160950e+05],\n",
       "        [  1.00000000e+00,   0.00000000e+00,   2.78929200e+04,\n",
       "           8.47107700e+04,   1.64470710e+05],\n",
       "        [  1.00000000e+00,   0.00000000e+00,   1.53441510e+05,\n",
       "           1.01145550e+05,   4.07934540e+05],\n",
       "        [  0.00000000e+00,   1.00000000e+00,   7.21076000e+04,\n",
       "           1.27864550e+05,   3.53183810e+05],\n",
       "        [  0.00000000e+00,   1.00000000e+00,   2.02295900e+04,\n",
       "           6.59479300e+04,   1.85265100e+05],\n",
       "        [  0.00000000e+00,   1.00000000e+00,   6.11363800e+04,\n",
       "           1.52701920e+05,   8.82182300e+04],\n",
       "        [  1.00000000e+00,   0.00000000e+00,   7.39945600e+04,\n",
       "           1.22782750e+05,   3.03319260e+05],\n",
       "        [  1.00000000e+00,   0.00000000e+00,   1.42107340e+05,\n",
       "           9.13917700e+04,   3.66168420e+05]]),\n",
       " array([  96778.92,   96479.51,  105733.54,   96712.8 ,  124266.9 ,\n",
       "         155752.6 ,  132602.65,   64926.08,   35673.41,  101004.64,\n",
       "         129917.04,   99937.59,   97427.84,  126992.93,   71498.49,\n",
       "         118474.03,   69758.98,  152211.77,  134307.35,  107404.34,\n",
       "         156991.12,  125370.37,   78239.91,   14681.4 ,  191792.06,\n",
       "         141585.52,   89949.14,  108552.04,  156122.51,  108733.99,\n",
       "          90708.19,  111313.02,  122776.86,  149759.96,   81005.76,\n",
       "          49490.75,  182901.99,  192261.83,   42559.73,   65200.33]),\n",
       " array([ 103282.38,  144259.4 ,  146121.95,   77798.83,  191050.39,\n",
       "         105008.31,   81229.06,   97483.56,  110352.25,  166187.94]))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)\n",
    "X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[ 1.73205081, -0.73379939, -0.35006454, -0.78547109,  0.1011968 ],\n",
       "        [-0.57735027,  1.36277029, -0.55530319, -1.48117426,  0.02734979],\n",
       "        [ 1.73205081, -0.73379939,  0.07935762,  0.80133381, -0.55152132],\n",
       "        [-0.57735027, -0.73379939, -0.54638238,  1.32505817,  0.07011684],\n",
       "        [ 1.73205081, -0.73379939,  0.43485371, -0.35598663,  0.75148516],\n",
       "        [ 1.73205081, -0.73379939,  1.26943143,  0.85518519,  0.98603118],\n",
       "        [ 1.73205081, -0.73379939,  1.04525007,  1.28077047,  0.4404    ],\n",
       "        [-0.57735027,  1.36277029, -1.529843  ,  0.02942065, -1.6218751 ],\n",
       "        [-0.57735027,  1.36277029, -1.53976251, -2.76767264, -1.6372965 ],\n",
       "        [-0.57735027,  1.36277029, -0.13115188,  1.14497701, -0.76949991],\n",
       "        [-0.57735027,  1.36277029,  0.92791613, -0.02992062,  0.48303162],\n",
       "        [ 1.73205081, -0.73379939, -0.20932933, -0.2993768 , -0.89915412],\n",
       "        [-0.57735027, -0.73379939, -0.17870828,  0.2251352 , -1.26401642],\n",
       "        [-0.57735027, -0.73379939,  0.1374709 , -0.06929437,  0.50384666],\n",
       "        [-0.57735027, -0.73379939, -1.03967624, -1.05076697, -0.43852106],\n",
       "        [-0.57735027, -0.73379939,  0.09938348, -0.36790317,  0.781818  ],\n",
       "        [-0.57735027,  1.36277029, -1.21580174,  0.15416247, -1.34947778],\n",
       "        [-0.57735027,  1.36277029,  1.05822437,  0.97836757,  0.88670051],\n",
       "        [-0.57735027, -0.73379939,  0.4401196 ,  0.46754749,  0.40923215],\n",
       "        [-0.57735027, -0.73379939, -0.15151937,  0.62430586, -0.51983056],\n",
       "        [-0.57735027,  1.36277029,  1.30361149, -0.91073517,  1.30179825],\n",
       "        [-0.57735027,  1.36277029,  0.49781135,  0.83770651,  0.65149135],\n",
       "        [-0.57735027, -0.73379939, -0.92897212, -0.18716957, -0.23769075],\n",
       "        [-0.57735027, -0.73379939, -1.55149779, -0.24751712, -1.27140496],\n",
       "        [-0.57735027, -0.73379939,  1.96871085,  1.08106713,  1.95818096],\n",
       "        [ 1.73205081, -0.73379939,  0.48063418,  0.15177059,  0.38634632],\n",
       "        [-0.57735027, -0.73379939, -0.59739193, -2.78544219, -0.04140287],\n",
       "        [-0.57735027,  1.36277029,  0.11649007, -0.93133851, -0.49867241],\n",
       "        [-0.57735027, -0.73379939,  1.36290079,  0.91964899, -0.60281921],\n",
       "        [ 1.73205081, -0.73379939, -0.08943162, -0.68142339,  0.83126112],\n",
       "        [ 1.73205081, -0.73379939, -0.93093295,  0.14156607, -0.00821485],\n",
       "        [-0.57735027,  1.36277029,  0.14561902,  1.1736151 ,  0.7905076 ],\n",
       "        [-0.57735027,  1.36277029,  0.31947194,  1.16359793, -1.6372965 ],\n",
       "        [-0.57735027, -0.73379939,  1.11867842, -0.56831342,  0.83298548],\n",
       "        [-0.57735027, -0.73379939, -0.71671353, -1.56095586, -0.21984184],\n",
       "        [ 1.73205081, -0.73379939, -1.52301833, -0.29261949,  0.76926327],\n",
       "        [-0.57735027,  1.36277029,  1.57413686, -0.18231009,  1.46653355],\n",
       "        [-0.57735027,  1.36277029,  2.02828029,  0.52173299,  2.18404776],\n",
       "        [-0.57735027, -0.73379939, -1.55149779,  0.46491495, -1.6372965 ],\n",
       "        [-0.57735027, -0.73379939, -1.07135402,  1.21350725, -1.40779169]]),\n",
       " array([[ 1.73205081, -0.73379939, -0.1214952 ,  2.2889053 , -0.68032287],\n",
       "        [-0.57735027, -0.73379939,  0.6280306 , -1.22069499,  0.38557774],\n",
       "        [ 1.73205081, -0.73379939,  0.65490061, -0.49434195,  0.21885524],\n",
       "        [ 1.73205081, -0.73379939, -0.94762148, -1.49417936, -0.30512104],\n",
       "        [ 1.73205081, -0.73379939,  1.77048111, -0.85932667,  1.6668808 ],\n",
       "        [-0.57735027,  1.36277029,  0.00961775,  0.17279112,  1.22341229],\n",
       "        [-0.57735027,  1.36277029, -1.11353109, -2.21896176, -0.13669119],\n",
       "        [-0.57735027,  1.36277029, -0.22790703,  1.13222416, -0.92274884],\n",
       "        [ 1.73205081, -0.73379939,  0.05047007, -0.02351175,  0.81952074],\n",
       "        [ 1.73205081, -0.73379939,  1.52509853, -1.23610162,  1.32858469]]))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "sc_X = StandardScaler()\n",
    "X_train = sc_X.fit_transform(X_train)\n",
    "X_test = sc_X.transform(X_test)\n",
    "X_train, X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=1, normalize=False)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "regressor = LinearRegression()\n",
    "regressor.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = regressor.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.formula.api as sm\n",
    "#X = np.insert(arr=X, obj=0, values=np.ones((X.shape[0], 1)).astype(int), axis=1)\n",
    "X = np.append(arr=np.ones((X.shape[0],1)).astype(int), values=X, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  1.000e+00,   0.000e+00,   1.000e+00,   1.653e+05,   1.369e+05,\n",
       "          4.718e+05],\n",
       "       [  1.000e+00,   0.000e+00,   0.000e+00,   1.626e+05,   1.514e+05,\n",
       "          4.439e+05],\n",
       "       [  1.000e+00,   1.000e+00,   0.000e+00,   1.534e+05,   1.011e+05,\n",
       "          4.079e+05],\n",
       "       [  1.000e+00,   0.000e+00,   1.000e+00,   1.444e+05,   1.187e+05,\n",
       "          3.832e+05],\n",
       "       [  1.000e+00,   1.000e+00,   0.000e+00,   1.421e+05,   9.139e+04,\n",
       "          3.662e+05],\n",
       "       [  1.000e+00,   0.000e+00,   1.000e+00,   1.319e+05,   9.981e+04,\n",
       "          3.629e+05],\n",
       "       [  1.000e+00,   0.000e+00,   0.000e+00,   1.346e+05,   1.472e+05,\n",
       "          1.277e+05],\n",
       "       [  1.000e+00,   1.000e+00,   0.000e+00,   1.303e+05,   1.455e+05,\n",
       "          3.239e+05],\n",
       "       [  1.000e+00,   0.000e+00,   1.000e+00,   1.205e+05,   1.487e+05,\n",
       "          3.116e+05],\n",
       "       [  1.000e+00,   0.000e+00,   0.000e+00,   1.233e+05,   1.087e+05,\n",
       "          3.050e+05],\n",
       "       [  1.000e+00,   1.000e+00,   0.000e+00,   1.019e+05,   1.106e+05,\n",
       "          2.292e+05],\n",
       "       [  1.000e+00,   0.000e+00,   0.000e+00,   1.007e+05,   9.179e+04,\n",
       "          2.497e+05],\n",
       "       [  1.000e+00,   1.000e+00,   0.000e+00,   9.386e+04,   1.273e+05,\n",
       "          2.498e+05],\n",
       "       [  1.000e+00,   0.000e+00,   0.000e+00,   9.199e+04,   1.355e+05,\n",
       "          2.527e+05],\n",
       "       [  1.000e+00,   1.000e+00,   0.000e+00,   1.199e+05,   1.565e+05,\n",
       "          2.565e+05],\n",
       "       [  1.000e+00,   0.000e+00,   1.000e+00,   1.145e+05,   1.226e+05,\n",
       "          2.618e+05],\n",
       "       [  1.000e+00,   0.000e+00,   0.000e+00,   7.801e+04,   1.216e+05,\n",
       "          2.643e+05],\n",
       "       [  1.000e+00,   0.000e+00,   1.000e+00,   9.466e+04,   1.451e+05,\n",
       "          2.826e+05],\n",
       "       [  1.000e+00,   1.000e+00,   0.000e+00,   9.175e+04,   1.142e+05,\n",
       "          2.949e+05],\n",
       "       [  1.000e+00,   0.000e+00,   1.000e+00,   8.642e+04,   1.535e+05,\n",
       "          0.000e+00],\n",
       "       [  1.000e+00,   0.000e+00,   0.000e+00,   7.625e+04,   1.139e+05,\n",
       "          2.987e+05],\n",
       "       [  1.000e+00,   0.000e+00,   1.000e+00,   7.839e+04,   1.538e+05,\n",
       "          2.997e+05],\n",
       "       [  1.000e+00,   1.000e+00,   0.000e+00,   7.399e+04,   1.228e+05,\n",
       "          3.033e+05],\n",
       "       [  1.000e+00,   1.000e+00,   0.000e+00,   6.753e+04,   1.058e+05,\n",
       "          3.048e+05],\n",
       "       [  1.000e+00,   0.000e+00,   1.000e+00,   7.704e+04,   9.928e+04,\n",
       "          1.406e+05],\n",
       "       [  1.000e+00,   0.000e+00,   0.000e+00,   6.466e+04,   1.396e+05,\n",
       "          1.380e+05],\n",
       "       [  1.000e+00,   1.000e+00,   0.000e+00,   7.533e+04,   1.441e+05,\n",
       "          1.341e+05],\n",
       "       [  1.000e+00,   0.000e+00,   1.000e+00,   7.211e+04,   1.279e+05,\n",
       "          3.532e+05],\n",
       "       [  1.000e+00,   1.000e+00,   0.000e+00,   6.605e+04,   1.826e+05,\n",
       "          1.181e+05],\n",
       "       [  1.000e+00,   0.000e+00,   1.000e+00,   6.561e+04,   1.530e+05,\n",
       "          1.071e+05],\n",
       "       [  1.000e+00,   1.000e+00,   0.000e+00,   6.199e+04,   1.156e+05,\n",
       "          9.113e+04],\n",
       "       [  1.000e+00,   0.000e+00,   1.000e+00,   6.114e+04,   1.527e+05,\n",
       "          8.822e+04],\n",
       "       [  1.000e+00,   0.000e+00,   0.000e+00,   6.341e+04,   1.292e+05,\n",
       "          4.609e+04],\n",
       "       [  1.000e+00,   1.000e+00,   0.000e+00,   5.549e+04,   1.031e+05,\n",
       "          2.146e+05],\n",
       "       [  1.000e+00,   0.000e+00,   0.000e+00,   4.643e+04,   1.577e+05,\n",
       "          2.108e+05],\n",
       "       [  1.000e+00,   0.000e+00,   1.000e+00,   4.601e+04,   8.505e+04,\n",
       "          2.055e+05],\n",
       "       [  1.000e+00,   1.000e+00,   0.000e+00,   2.866e+04,   1.271e+05,\n",
       "          2.011e+05],\n",
       "       [  1.000e+00,   0.000e+00,   0.000e+00,   4.407e+04,   5.128e+04,\n",
       "          1.970e+05],\n",
       "       [  1.000e+00,   0.000e+00,   1.000e+00,   2.023e+04,   6.595e+04,\n",
       "          1.853e+05],\n",
       "       [  1.000e+00,   0.000e+00,   0.000e+00,   3.856e+04,   8.298e+04,\n",
       "          1.750e+05],\n",
       "       [  1.000e+00,   0.000e+00,   0.000e+00,   2.875e+04,   1.185e+05,\n",
       "          1.728e+05],\n",
       "       [  1.000e+00,   1.000e+00,   0.000e+00,   2.789e+04,   8.471e+04,\n",
       "          1.645e+05],\n",
       "       [  1.000e+00,   0.000e+00,   0.000e+00,   2.364e+04,   9.619e+04,\n",
       "          1.480e+05],\n",
       "       [  1.000e+00,   0.000e+00,   1.000e+00,   1.551e+04,   1.274e+05,\n",
       "          3.553e+04],\n",
       "       [  1.000e+00,   0.000e+00,   0.000e+00,   2.218e+04,   1.548e+05,\n",
       "          2.833e+04],\n",
       "       [  1.000e+00,   0.000e+00,   1.000e+00,   1.000e+03,   1.242e+05,\n",
       "          1.904e+03],\n",
       "       [  1.000e+00,   1.000e+00,   0.000e+00,   1.315e+03,   1.158e+05,\n",
       "          2.971e+05],\n",
       "       [  1.000e+00,   0.000e+00,   0.000e+00,   0.000e+00,   1.354e+05,\n",
       "          0.000e+00],\n",
       "       [  1.000e+00,   0.000e+00,   1.000e+00,   5.420e+02,   5.174e+04,\n",
       "          0.000e+00],\n",
       "       [  1.000e+00,   0.000e+00,   0.000e+00,   0.000e+00,   1.170e+05,\n",
       "          4.517e+04]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.set_printoptions(precision=3)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SL = 0.05 # significance level\n",
    "\n",
    "X_indecies = [0,1,2,3,4,5]\n",
    "X_opt = X[:, X_indecies]\n",
    "regressor_OLS = sm.OLS(endog=y, exog=X_opt).fit()\n",
    "while max(regressor_OLS.pvalues) > SL:\n",
    "    large_pvalue = np.where(regressor_OLS.pvalues==max(regressor_OLS.pvalues))[0][0]\n",
    "    print(large_pvalue)\n",
    "    X_indecies.remove(large_pvalue)\n",
    "    X_indecies = list(map(lambda x: x-1 if x> large_pvalue else x, X_indecies))\n",
    "    X_opt = X[:, X_indecies]\n",
    "    regressor_OLS = sm.OLS(endog=y, exog=X_opt).fit()\n",
    "\n",
    "\n",
    "X_opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3, 4, 5, 5, 6]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
