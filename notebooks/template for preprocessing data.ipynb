{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This is a template for pre porcessing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First thing you want to do is get the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WindowsPath('D:/Workspace/machine-learning-study/notebooks')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#creates a path object with the current directory\n",
    "import os\n",
    "from pathlib import Path\n",
    "current_dir = Path(os.getcwd())\n",
    "current_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'D:\\\\Workspace\\\\machine-learning-study\\\\Machine Learning A-Z Template Folder/Part 1 - Data Preprocessing/Data_Preprocessing/Data.csv'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#goes on directory up \n",
    "w_dir = str(current_dir.parents[0])\n",
    "#we will take as an example \\Machine Learning A-Z Template Folder\\Part 1 - Data Preprocessing\\Data_Preprocessing\n",
    "#make sure to take of the first \\ because if it is left there then it is considered an absolute path...\n",
    "data_url = r'Machine Learning A-Z Template Folder/Part 1 - Data Preprocessing/Data_Preprocessing/Data.csv'\n",
    "path = os.path.join(w_dir, data_url)\n",
    "path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### With that we can get the data using pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Country</th>\n",
       "      <th>Age</th>\n",
       "      <th>Salary</th>\n",
       "      <th>Purchased</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>France</td>\n",
       "      <td>44.0</td>\n",
       "      <td>72000.0</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Spain</td>\n",
       "      <td>27.0</td>\n",
       "      <td>48000.0</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Germany</td>\n",
       "      <td>30.0</td>\n",
       "      <td>54000.0</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Spain</td>\n",
       "      <td>38.0</td>\n",
       "      <td>61000.0</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Germany</td>\n",
       "      <td>40.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Country   Age   Salary Purchased\n",
       "0   France  44.0  72000.0        No\n",
       "1    Spain  27.0  48000.0       Yes\n",
       "2  Germany  30.0  54000.0        No\n",
       "3    Spain  38.0  61000.0        No\n",
       "4  Germany  40.0      NaN       Yes"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(path) # this file is correctly formatted and so no other parameters need to be added\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now we need to take the data and split it into independent params(X) and dependent params(y)\n",
    "### we use the values of X to figure out the corresponding y's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#iloc is used for multi-indexing, the first : is for rows the second for cols\n",
    "#which means the next line takes all the values of the rows and takes off the last col\n",
    "X = data.iloc[:, :-1].values\n",
    "y = data.iloc[:, data.shape[1]-1].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We need to make sure that our data set is not missing data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lets look at row four in X as an example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Germany', 40.0, nan], dtype=object)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[4] #as we can the third value is NaN, we take care of this by taking the mean of that column and inserting that value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['France', 44.0, 72000.0],\n",
       "       ['Spain', 27.0, 48000.0],\n",
       "       ['Germany', 30.0, 54000.0],\n",
       "       ['Spain', 38.0, 61000.0],\n",
       "       ['Germany', 40.0, 63777.77777777778],\n",
       "       ['France', 35.0, 58000.0],\n",
       "       ['Spain', 38.77777777777778, 52000.0],\n",
       "       ['France', 48.0, 79000.0],\n",
       "       ['Germany', 50.0, 83000.0],\n",
       "       ['France', 37.0, 67000.0]], dtype=object)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import Imputer\n",
    "imputer = Imputer(missing_values='NaN', strategy ='mean', axis=0) # axis 0 is the cols for some reason\n",
    "imputer = imputer.fit(X[:, 1:3]) # the cols in which we want to make sure there are no missing values\n",
    "X[:, 1:3] = imputer.transform(X[:, 1:3])\n",
    "X # as we can se now the values which were NaN have been turned into the mean of the col"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Another problem we face is the algrothims take only numerical data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### this means that we cannot have cols which have string values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 2, 1, 2, 1, 0, 2, 0, 1, 0], dtype=object),\n",
       " array([0, 1, 0, 0, 1, 1, 0, 1, 0, 1], dtype=int64))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#for example: this first col in X is a range between France, Spain, Germany\n",
    "#we can solve this by encoding the data\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "labelencoder_X = LabelEncoder()\n",
    "X[:, 0] = labelencoder_X.fit_transform(X[:, 0])\n",
    "y = labelencoder_X.fit_transform(y)\n",
    "X[:, 0], y # as we can see the data is turned in to numerical values that we can work with (France = 0, Spain = 2, Germany = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### With the encoding we face another problem, the algorithm will be biased towards higher values and so it would not work as we wanted to"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  1.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          4.40000000e+01,   7.20000000e+04],\n",
       "       [  0.00000000e+00,   0.00000000e+00,   1.00000000e+00,\n",
       "          2.70000000e+01,   4.80000000e+04],\n",
       "       [  0.00000000e+00,   1.00000000e+00,   0.00000000e+00,\n",
       "          3.00000000e+01,   5.40000000e+04],\n",
       "       [  0.00000000e+00,   0.00000000e+00,   1.00000000e+00,\n",
       "          3.80000000e+01,   6.10000000e+04],\n",
       "       [  0.00000000e+00,   1.00000000e+00,   0.00000000e+00,\n",
       "          4.00000000e+01,   6.37777778e+04],\n",
       "       [  1.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          3.50000000e+01,   5.80000000e+04],\n",
       "       [  0.00000000e+00,   0.00000000e+00,   1.00000000e+00,\n",
       "          3.87777778e+01,   5.20000000e+04],\n",
       "       [  1.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          4.80000000e+01,   7.90000000e+04],\n",
       "       [  0.00000000e+00,   1.00000000e+00,   0.00000000e+00,\n",
       "          5.00000000e+01,   8.30000000e+04],\n",
       "       [  1.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          3.70000000e+01,   6.70000000e+04]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#to solve this we can encode the values again this time creating a col for each option with the value one where the data fits\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "onehotencoder = OneHotEncoder(categorical_features = [0]) # we give it the cols where we want the encoding to happen\n",
    "X = onehotencoder.fit_transform(X).toarray()\n",
    "#notice that we dont need to say which cols because we gave the correct \n",
    "#cols in the consturctor\n",
    "#we also dont need to do this for y because it only has 2 values 0,1\n",
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We dont want to overfit the data so we split it up to training data, and testing data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### overfitting data means that the algorithm nows the data well but doesnt learn the logic, memorizes the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[  0.00000000e+00,   1.00000000e+00,   0.00000000e+00,\n",
       "           4.00000000e+01,   6.37777778e+04],\n",
       "        [  1.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "           3.70000000e+01,   6.70000000e+04],\n",
       "        [  0.00000000e+00,   0.00000000e+00,   1.00000000e+00,\n",
       "           2.70000000e+01,   4.80000000e+04],\n",
       "        [  0.00000000e+00,   0.00000000e+00,   1.00000000e+00,\n",
       "           3.87777778e+01,   5.20000000e+04],\n",
       "        [  1.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "           4.80000000e+01,   7.90000000e+04],\n",
       "        [  0.00000000e+00,   0.00000000e+00,   1.00000000e+00,\n",
       "           3.80000000e+01,   6.10000000e+04],\n",
       "        [  1.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "           4.40000000e+01,   7.20000000e+04],\n",
       "        [  1.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "           3.50000000e+01,   5.80000000e+04]]),\n",
       " array([[  0.00000000e+00,   1.00000000e+00,   0.00000000e+00,\n",
       "           3.00000000e+01,   5.40000000e+04],\n",
       "        [  0.00000000e+00,   1.00000000e+00,   0.00000000e+00,\n",
       "           5.00000000e+01,   8.30000000e+04]]),\n",
       " array([1, 1, 1, 0, 1, 0, 0, 1], dtype=int64),\n",
       " array([0, 0], dtype=int64))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)\n",
    "X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Last but not least we need to feature scale the data, this means we make all the values range from -1 to 1 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### we do this to make sure the data handels each col with out bais, as again, bigger values have bigger impact on the algorithim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### this will also make it eaiser for the algorithm to work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[-1.        ,  2.64575131, -0.77459667,  0.26306757,  0.12381479],\n",
       "        [ 1.        , -0.37796447, -0.77459667, -0.25350148,  0.46175632],\n",
       "        [-1.        , -0.37796447,  1.29099445, -1.97539832, -1.53093341],\n",
       "        [-1.        , -0.37796447,  1.29099445,  0.05261351, -1.11141978],\n",
       "        [ 1.        , -0.37796447, -0.77459667,  1.64058505,  1.7202972 ],\n",
       "        [-1.        , -0.37796447,  1.29099445, -0.0813118 , -0.16751412],\n",
       "        [ 1.        , -0.37796447, -0.77459667,  0.95182631,  0.98614835],\n",
       "        [ 1.        , -0.37796447, -0.77459667, -0.59788085, -0.48214934]]),\n",
       " array([[-1.        ,  2.64575131, -0.77459667, -1.45882927, -0.90166297],\n",
       "        [-1.        ,  2.64575131, -0.77459667,  1.98496442,  2.13981082]]))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "sc_X = StandardScaler()\n",
    "X_train = sc_X.fit_transform(X_train)\n",
    "X_test = sc_X.transform(X_test)\n",
    "X_train, X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
